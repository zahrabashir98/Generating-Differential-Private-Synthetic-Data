{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PATE_TEST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jjwZ1EUBLoO",
        "outputId": "06a2ce12-743a-4871-af8b-5e23af955c42"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWX-kKrA0ot2"
      },
      "source": [
        "# Load Real Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2KoMevBBIKE",
        "outputId": "dd4b1271-a753-4f09-9904-745d45879d45"
      },
      "source": [
        "from pandas import read_csv\n",
        "from scipy.special import expit\n",
        "from sklearn.utils import shuffle\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def load_dataset_train(full_path = '/content/drive/MyDrive/Privacy/real_data_train.csv'):\n",
        "  # load the dataset as a numpy array\n",
        "  with open(full_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  # retrieve numpy array\n",
        "  data = data.values\n",
        "  # split into input and output elements\n",
        "  X, y = data[:, :-1], data[:, -1]\n",
        "  return X, y\n",
        "\n",
        "X_train, y_train = load_dataset_train()\n",
        "X_train = expit(X_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_train[0])\n",
        "\n",
        "\n",
        "def load_dataset_test(full_path = '/content/drive/MyDrive/Privacy/real_data_test.csv'):\n",
        "  # load the dataset as a numpy array\n",
        "  with open(full_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  # retrieve numpy array\n",
        "  data = data.values\n",
        "  # split into input and output elements\n",
        "  X, y = data[:, :-1], data[:, -1]\n",
        "  return X, y\n",
        "\n",
        "X_test, y_test = load_dataset_test()\n",
        "X_test = expit(X_test)\n",
        "# X_test = np.concatenate([X_test, X_train[:200]])\n",
        "# y_test = np.concatenate([y_test, y_train[:200]])\n",
        "print(X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 4) (1000,)\n",
            "[0.99411941 0.99982842 0.05258531 0.18114637]\n",
            "(572, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irIXZNFm03d6"
      },
      "source": [
        "# Load Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ry_1QzzBRxL",
        "outputId": "293422bc-832f-4b50-a68e-49b935d171ea"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Privacy/generated data with pate/pate_neg_x_low4000.csv\", 'rb') as f:\n",
        "    data1 = pickle.load(f)\n",
        "df1 = pd.DataFrame(data1, columns = [i for i in range(data1.shape[1])])\n",
        "\n",
        "print(df1.shape)\n",
        "with open(\"/content/drive/MyDrive/Privacy/generated data with pate/pate_pos_x_low4000.csv\", 'rb') as f:\n",
        "    data2 = pickle.load(f)\n",
        "df2 = pd.DataFrame(data2, columns = [i for i in range(data2.shape[1])])\n",
        "print(df2.shape)\n",
        "\n",
        "y_train = np.array([1 for i in range(len(df1))] + [0 for i in range(len(df2)) ])\n",
        "print(len(y_train))\n",
        "\n",
        "# Concat negative and positive data, and shuffle\n",
        "result = pd.concat([df1, df2])\n",
        "X_train_pate, y_train_pate = shuffle(result, y_train)\n",
        "\n",
        "print(X_train_pate.shape)\n",
        "print(y_train_pate.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 4)\n",
            "(2000, 4)\n",
            "4000\n",
            "(4000, 4)\n",
            "(4000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42pEXRhW1lgL"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEUHRMJGMB5y"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import tensorflow as tf\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "Dense(input_dim = 4, units = 2, activation = 'relu'),\n",
        "Dense(units = 10, activation = 'relu'),\n",
        "Dropout(0.2),\n",
        "# Dense(units = 10, activation = 'relu'),\n",
        "Dense(units = 4, activation = 'relu'),\n",
        "Dense(units =1, activation = 'sigmoid'),])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibKdJwFS1XG9"
      },
      "source": [
        "# Evaluate Private Data Generation Using a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY7cu1KnoaN4",
        "outputId": "4b90d613-25fa-4c2d-c1fb-4a4bc3fc3c82"
      },
      "source": [
        "#evaluate the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy', f1_m, precision_m, recall_m])\n",
        "model.fit(X_train_pate, y_train_pate, batch_size = 5, epochs = 10)\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(loss, accuracy, f1_score, precision, recall)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5339 - accuracy: 0.7930 - f1_m: 0.8010 - precision_m: 0.7309 - recall_m: 0.9534\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2203 - accuracy: 0.9979 - f1_m: 0.9725 - precision_m: 0.9711 - recall_m: 0.9752\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1315 - accuracy: 0.9984 - f1_m: 0.9711 - precision_m: 0.9720 - recall_m: 0.9705\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9973 - f1_m: 0.9785 - precision_m: 0.9786 - recall_m: 0.9797\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0586 - accuracy: 0.9985 - f1_m: 0.9709 - precision_m: 0.9712 - recall_m: 0.9710\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0389 - accuracy: 1.0000 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9644\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0278 - accuracy: 0.9989 - f1_m: 0.9596 - precision_m: 0.9613 - recall_m: 0.9587\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0194 - accuracy: 0.9996 - f1_m: 0.9725 - precision_m: 0.9728 - recall_m: 0.9722\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0151 - accuracy: 0.9991 - f1_m: 0.9634 - precision_m: 0.9641 - recall_m: 0.9628\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.9995 - f1_m: 0.9726 - precision_m: 0.9730 - recall_m: 0.9723\n",
            "1.1753512620925903 0.7150349617004395 0.5264100432395935 0.907561719417572 0.38300126791000366\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}